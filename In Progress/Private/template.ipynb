{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnKRe0p9h35K"
      },
      "source": [
        "# TASK #1: UNDERSTAND THE PROBLEM STATEMENT AND BUSINESS CASE  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsz3Vbnt40J5"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1mVeeFi7cusk7ljpMf0cSSjLvi0Z3gaEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIS1I-HMnQXC"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1gYn6Dyi7mL1RDbZQzTKuirkw7GnbWwK6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr6pOOh0hHaj"
      },
      "source": [
        "# TASK #2: IMPORT MODEL WITH PRE-TRAINED WEIGHTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "QqPjanlXkVzi",
        "outputId": "353a6a9c-754a-4b8b-cdc0-9f7438bce859"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random \n",
        "import os\n",
        "import PIL.Image\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image # Python Image Library is a library that adds support for opening, manipulating, and saving many different\n",
        "                      # image file formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BFvyg3SPHpj8",
        "outputId": "1143dbe4-37ee-480d-82db-407ac1bf0aca"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmH2HBHiGtP1"
      },
      "outputs": [],
      "source": [
        "# Loading trained inceptionNet model, imagenet (include_top=False)\n",
        "base_model = tf.keras.applications.InceptionV3(include_top = True, weights = 'imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading trained inceptionNet model, imagenet (include_top=True) <br>\n",
        "base_model = tf.keras.applications.InceptionV3(include_top = <b>True</b>, weights = 'imagenet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9mGAe_dC5Q7"
      },
      "source": [
        "MINI CHALLENGE #1: \n",
        "- How many total parameters exist in inceptionNet V3?\n",
        "- Set include top = True and indicate how many total parameters exist now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2_1Hu9RO7NZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWb45OshSDsr"
      },
      "source": [
        "# TASK #3: GET AN IMAGE AND PRE-PROCESS IT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MQ7wy4q5J2e"
      },
      "outputs": [],
      "source": [
        "# Open the first image\n",
        "# Source: https://www.pxfuel.com/en/free-photo-xxgfs\n",
        "img_1 = Image.open(\"/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/mars.jpg\")\n",
        "\n",
        "# Open the second image\n",
        "# Source: https://commons.wikimedia.org/wiki/File:Georges_Garen_embrasement_tour_Eiffel.jpg\n",
        "img_2 = Image.open('/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/eiffel.jpg')\n",
        "\n",
        "# Blend the two images\n",
        "\n",
        "image = Image.blend(img_1, img_2, 0.5) # alpha --> The interpolation alpha factor. If alpha is 0.0, a copy of the first image is returned.\n",
        "# If alpha is 1.0, a copy of the second image is returned. \n",
        "\n",
        "# Save the blended image\n",
        "image.save(\"img_0.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIy4GhP45yuT"
      },
      "outputs": [],
      "source": [
        "# Load the image\n",
        "Sample_Image = tf.keras.preprocessing.image.load_img('img_0.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "Mzs7ZirEJdkZ",
        "outputId": "77e5e982-9570-413c-faee-74a0c498fc9a"
      },
      "outputs": [],
      "source": [
        "Sample_Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X7EdBGZPjpdm",
        "outputId": "fa53c1a5-66e0-412e-ca53-53fdec7717c9"
      },
      "outputs": [],
      "source": [
        "# Get the shape of the image\n",
        "np.shape(Sample_Image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tB1IRmzVJuSL",
        "outputId": "570ead03-aadd-47a9-d344-43a573b7edcf"
      },
      "outputs": [],
      "source": [
        "# Check out the type of the image\n",
        "type(Sample_Image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnpbyRXV-DmQ"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array\n",
        "Sample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)\n",
        "\n",
        "# Sample_Image = np.array(Sample_Image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bZH-uBrrKMg_",
        "outputId": "a96b8d4e-a745-434c-f7fd-e40bf3adfecd"
      },
      "outputs": [],
      "source": [
        "# Confirm that the image is converted to Numpy array\n",
        "type(Sample_Image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LopInguJKOj5",
        "outputId": "81b492ba-5d15-4074-a06f-e732fbe4cb6f"
      },
      "outputs": [],
      "source": [
        "# Obtain the max and min values\n",
        "print('min pixel values = {}, max pixel values = {}'.format(Sample_Image.min(), Sample_Image.max()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NUjlzcIBMAGS",
        "outputId": "6c259653-fb83-4a71-cbb5-c091662049aa"
      },
      "outputs": [],
      "source": [
        "# Normalize the input image\n",
        "Sample_Image = np.array(Sample_Image)/255.0\n",
        "Sample_Image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dffJyzy6KyFG",
        "outputId": "fb3437ce-7f0b-4c77-9350-b0422de84c05"
      },
      "outputs": [],
      "source": [
        "# Let's verify normalized images values!\n",
        "print('min pixel values = {}, max pixel values = {}'.format(Sample_Image.min(), Sample_Image.max()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dpwAwVDPIKO"
      },
      "outputs": [],
      "source": [
        "Sample_Image = tf.expand_dims(Sample_Image, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YSY7HAHjPKNH",
        "outputId": "f79ccc6b-0295-43c2-8ca5-04c9c1c0b4e3"
      },
      "outputs": [],
      "source": [
        "np.shape(Sample_Image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5F2mIIZwvjY"
      },
      "source": [
        "MINI CHALLENGE #2: \n",
        "- Perform the opposite of expand dimension \n",
        "- Plot the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HZEtUT-xF0J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt3_WsRJ7Bi-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh5YVgd3NJkz"
      },
      "source": [
        "# TASK #4: RUN THE PRETRAINED MODEL AND EXPLORE ACTIVATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CVnUcoEz4sp"
      },
      "source": [
        "# NOTES:\n",
        "- Select a layer and attempt at maximizing the loss which is the activations generated by the layer of interest.\n",
        "- We can select any layer we choose, early layers generate simple features such as edges and deep layers generate more complex features such as entire face, car or tree.\n",
        "- Inception network has multiple concatenated layers named 'mixed' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9vJzenNu71J8",
        "outputId": "7d9f6218-4cbb-4102-b5b1-ccd7d63dcae9"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3cxzeLpGtMH"
      },
      "outputs": [],
      "source": [
        "# Maximize the activations of these layers\n",
        "\n",
        "names = ['mixed3', 'mixed5', 'mixed7']\n",
        "\n",
        "# names = ['mixed3']\n",
        "\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "deepdream_model = tf.keras.Model(inputs = base_model.input, outputs = layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pKtOzXEAEdgK",
        "outputId": "5133ee58-928d-4e0d-adf6-637644e04755"
      },
      "outputs": [],
      "source": [
        "deepdream_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uf2tCdV5Nsez",
        "outputId": "d5c6ea52-bfc4-4322-e52d-a0daf936b5cb"
      },
      "outputs": [],
      "source": [
        "# Let's run the model by feeding in our input image and taking a look at the activations \"Neuron outputs\"\n",
        "activations = deepdream_model(Sample_Image)\n",
        "activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a-liG_NweWcv",
        "outputId": "f5e30731-9bbb-4c7c-acb7-ed2c5b87b3c8"
      },
      "outputs": [],
      "source": [
        "len(activations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPy-ST-BONCK"
      },
      "source": [
        "MINI CHALLENGE #3: \n",
        "- Generate the activations for a deeper layer such as 'mixed8' and 'mixed9'.\n",
        "- What is the size of the generated activations?\n",
        "- Combine 4 activations from early and deeper layers such as 'mixed3', 'mixed5', 'mixed8', 'mixed9'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K7IpNQxOMDO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H38yzWMAn7hu"
      },
      "source": [
        "# TASK #5: UNDERSTAND HOW DEEP DREAM ALGORITHM WORKS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAZlu2NFnQjw"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1pbBZWp8JCgIWBzrXhDoQZSi5ekeR2Sga)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itQpoqoUAUMP"
      },
      "source": [
        "Source #1: https://www.topbots.com/advanced-topics-deep-convolutional-neural-networks/\n",
        "\n",
        "Source #2: https://wccftech.com/nvidia-demo-skynet-gtc-2014-neural-net-based-machine-learning-intelligence/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3vsHlOSnQq4"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1mh4OUKw5cFjxFa7zW-JZyLwHAQHRIW_-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fR1aakPnQu1"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1k1Hp6M1GB9qCaiPPAJQgGwTh5VNzEm4l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHoxRhkSnQyk"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1usz7K6Bmo_9u7n56NV3PCvLBRgSN1TkQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C6jSzklnRAV"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1R7_C4r4vy2tqIB5Pi-ltyY2N_WC6jSYF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2FN_uwz5DqT"
      },
      "source": [
        "# TASK #6: UNDERSTAND HOW TO PERFORM GRADIENT CALCULATION AND TF.GRADIENTTAPE()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "614ia_UW4ENa"
      },
      "source": [
        "- tf.GradientTape() is used to record operations for automatic differentiation\n",
        "- For example, Let's assume we have the following functions y = x^3. \n",
        "- The gradient at x = 2 can be computed as follows: dy_dx = 3 * x^2 = 3 * 2^2 = 12. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQoqmrhZYWtn"
      },
      "outputs": [],
      "source": [
        "x = tf.constant(2.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsnKsx3d3pXV"
      },
      "outputs": [],
      "source": [
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = x * x * x\n",
        "dy_dx = g.gradient(y, x) # Will compute to 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w1CPH8E43ylF",
        "outputId": "f97ad375-7edb-484d-945a-adeb205cc903"
      },
      "outputs": [],
      "source": [
        "dy_dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQkTP3gAxg-c"
      },
      "source": [
        "MINI CHALLENGE #4: \n",
        "- Using tf.GradientTape(), calculate the gradient of y = x^4 + x^5 at x = 5\n",
        "- Verify your answer by manually differentation the equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUiZrxKEIuWT"
      },
      "outputs": [],
      "source": [
        "x = tf.constant(5.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2EpHmkPNxdCL",
        "outputId": "eac751fc-cda6-4c72-d2c2-d0545d5577f9"
      },
      "outputs": [],
      "source": [
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = (x * x * x * x) + (x * x * x * x * x)  \n",
        "dy_dx = g.gradient(y, x) \n",
        "dy_dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZcbcENxu_45"
      },
      "source": [
        "# TASK #7: IMPLEMENT DEEP DREAM ALGORITHM - STEP #1 LOSS CALCULATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daBEmuXpYARn"
      },
      "source": [
        "- CREDITS: The DeepDream Code has been adopted from Keras Documentation:\n",
        "- https://www.tensorflow.org/tutorials/generative/deepdream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "65Nc3SVZRZCF",
        "outputId": "415c86ae-c2a7-4368-898d-9bfe7ecd6b4b"
      },
      "outputs": [],
      "source": [
        "# Since the cal_closs function includes expand dimension, let's squeeze the image (reduce_dims)\n",
        "Sample_Image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyC4T7y7RQxa"
      },
      "outputs": [],
      "source": [
        "Sample_Image = tf.squeeze(Sample_Image, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZEW6nOUtRcVV",
        "outputId": "b93f5a5e-f6f0-482b-c716-fbdafe0da0cd"
      },
      "outputs": [],
      "source": [
        "Sample_Image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq1BtOp3GPIG"
      },
      "outputs": [],
      "source": [
        "def calc_loss(image, model):\n",
        "# Function used for loss calculations\n",
        "# It works by feedforwarding the input image through the network and generate activations\n",
        "# Then obtain the average and sum of those outputs\n",
        "\n",
        "  img_batch = tf.expand_dims(image, axis=0) # Convert into batch format\n",
        "  layer_activations = model(img_batch) # Run the model\n",
        "  print('ACTIVATION VALUES (LAYER OUTPUT) =\\n', layer_activations)\n",
        "  # print('ACTIVATION SHAPE =\\n', np.shape(layer_activations))\n",
        "\n",
        "  losses = [] # accumulator to hold all the losses\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act) # calculate mean of each activation \n",
        "    losses.append(loss)\n",
        "  \n",
        "  print('LOSSES (FROM MULTIPLE ACTIVATION LAYERS) = ', losses)\n",
        "  print('LOSSES SHAPE (FROM MULTIPLE ACTIVATION LAYERS) = ', np.shape(losses))\n",
        "  print('SUM OF ALL LOSSES (FROM ALL SELECTED LAYERS)= ', tf.reduce_sum(losses))\n",
        "\n",
        "  return  tf.reduce_sum(losses) # Calculate sum "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mIgt-O8WGPDd",
        "outputId": "07489760-cd70-4d42-e96e-6758b34033f5"
      },
      "outputs": [],
      "source": [
        "loss = calc_loss(tf.Variable(Sample_Image), deepdream_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YVdP36WrH_Vj",
        "outputId": "c3370522-25e1-4efa-b173-4a95ea0d1bf7"
      },
      "outputs": [],
      "source": [
        "loss # Sum up the losses from both activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOMSKpAtztK8"
      },
      "source": [
        "MINI CHALLENGE #5: \n",
        "- What is the sum of all losses when 'mixed3' layer is the only layer used for activations generation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRC01ey2zsK4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Sz8_stSHW3"
      },
      "source": [
        "# TASK #8: IMPLEMENT DEEP DREAM ALGORITHM - STEP #2 (CALCULATE THE GRADIENT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCLZJTMO1EpN"
      },
      "source": [
        "- In this step, we will rely on the loss that has been calculated in the previous step and calculate the gradient with respect to the given input image and then add it to the input original image. \n",
        "- Doing so iteratively will result in feeding images that continiously and increasingly excite the neurons and generate more dreamy like images!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr4k5RStOKLi"
      },
      "outputs": [],
      "source": [
        "# When you annotate a function with tf.function, the function can be called like any other python defined function. \n",
        "# The benefit is that it will be compiled into a graph so it will be much faster and could be executed over TPU/GPU\n",
        "\n",
        "@tf.function\n",
        "def deepdream(model, image, step_size):\n",
        "    with tf.GradientTape() as tape:\n",
        "      # This needs gradients relative to `img`\n",
        "      # `GradientTape` only watches `tf.Variable`s by default\n",
        "      tape.watch(image)\n",
        "      loss = calc_loss(image, model) # call the function that calculate the loss \n",
        "\n",
        "    # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "    # The syntax is as follows: dy_dx = g.gradient(y, x) \n",
        "    gradients = tape.gradient(loss, image)\n",
        "\n",
        "    print('GRADIENTS =\\n', gradients)\n",
        "    print('GRADIENTS SHAPE =\\n', np.shape(gradients))\n",
        "\n",
        "    # tf.math.reduce_std computes the standard deviation of elements across dimensions of a tensor\n",
        "    gradients /= tf.math.reduce_std(gradients)  \n",
        "\n",
        "    # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "    # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "    image = image + gradients * step_size\n",
        "    image = tf.clip_by_value(image, -1, 1)\n",
        "\n",
        "    return loss, image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQouIa0Ragzr"
      },
      "outputs": [],
      "source": [
        "def run_deep_dream_simple(model, image, steps = 100, step_size = 0.01):\n",
        "  # Convert from uint8 to the range expected by the model.\n",
        "  image = tf.keras.applications.inception_v3.preprocess_input(image)\n",
        "\n",
        "  for step in range(steps):\n",
        "    loss, image = deepdream(model, image, step_size)\n",
        "    \n",
        "    if step % 100 == 0:\n",
        "      plt.figure(figsize=(12,12))\n",
        "      plt.imshow(deprocess(image))\n",
        "      plt.show()\n",
        "      print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "  # clear_output(wait=True)\n",
        "  plt.figure(figsize=(12,12))\n",
        "  plt.imshow(deprocess(image))\n",
        "  plt.show()\n",
        "\n",
        "  return deprocess(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG-50Tm2axFu"
      },
      "outputs": [],
      "source": [
        "def deprocess(image):\n",
        "  image = 255*(image + 1.0)/2.0\n",
        "  return tf.cast(image, tf.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qg3oohvSa6HK",
        "outputId": "687e7f20-e7fd-42b0-9acc-7cdec441ad91"
      },
      "outputs": [],
      "source": [
        "Sample_Image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-7OqBQu8akWT",
        "outputId": "ad632101-d2cb-4cd3-94d1-19ef0386735f"
      },
      "outputs": [],
      "source": [
        "# Let's Load the image again and convert it to Numpy array \n",
        "Sample_Image = np.array(tf.keras.preprocessing.image.load_img('img_0.jpg'))\n",
        "dream_img = run_deep_dream_simple(model = deepdream_model, image = Sample_Image, steps = 4000, step_size = 0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn1A9cTpFc-t"
      },
      "source": [
        "# TASK #9: (VIDEO) APPLY DEEPDREAM TO GENERATE A SERIES OF IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9ubTEFTK_Zv"
      },
      "outputs": [],
      "source": [
        "image = tf.keras.preprocessing.image.load_img(\"img_0.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "xZXtwuZnLAMB",
        "outputId": "bd0e5d65-c824-4362-babb-e457feea6f6e"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6YEv4BEFmqs"
      },
      "outputs": [],
      "source": [
        "# Name of the folder\n",
        "dream_name = 'mars_eiffel'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAuR_5F8QsV3"
      },
      "outputs": [],
      "source": [
        "# Blended image dimension\n",
        "\n",
        "x_size = 910 # larger the image longer is going to take to fetch the frames \n",
        "y_size = 605"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-ueNUQ1Fu1f"
      },
      "outputs": [],
      "source": [
        "# Define Counters \n",
        "created_count = 0\n",
        "max_count = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C__-w3lYVbjO"
      },
      "outputs": [],
      "source": [
        "# This helper function loads an image and returns it as a numpy array of floating points\n",
        "\n",
        "def load_image(filename):\n",
        "    image = PIL.Image.open(filename)\n",
        "    return np.float32(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2zrAdxiEFu3u",
        "outputId": "c4e19fba-97ae-4fb9-e3bd-5b90e96e67ac"
      },
      "outputs": [],
      "source": [
        "for i in range(0, 50):\n",
        "    # Make sure to create a new folder entitled 'mars_eiffel' and place img_0 in it\n",
        "    # Get into the dream directory and look for the number of images and then figure out what is the latest image. Hence this \n",
        "    # image we are going to start with and let it dream on and on\n",
        "     \n",
        "    if os.path.isfile('/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i+1)):\n",
        "        print(\"{} present already, continue fetching the frames...\".format(i+1))\n",
        "        \n",
        "    else:\n",
        "        # Call the load image funtion\n",
        "        img_result = load_image(r'/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i))\n",
        "\n",
        "    \n",
        "        # Zoom the image \n",
        "        x_zoom = 2 # this indicates how quick the zoom is \n",
        "        y_zoom = 1\n",
        "        \n",
        "        # Chop off the edges of the image and resize the image back to the original shape. This gives the visual changes of a zoom\n",
        "        img_result = img_result[0+x_zoom : y_size-y_zoom, 0+y_zoom : x_size-x_zoom]\n",
        "        img_result = cv2.resize(img_result, (x_size, y_size))\n",
        "        \n",
        "        # Adjust the RGB value of the image\n",
        "        img_result[:, :, 0] += 2  # red\n",
        "        img_result[:, :, 1] += 2  # green\n",
        "        img_result[:, :, 2] += 2  # blue\n",
        "        \n",
        "        # Deep dream model  \n",
        "        img_result = run_deep_dream_simple(model = deepdream_model, image = img_result, steps = 500, step_size = 0.001)\n",
        "        \n",
        "        # Clip the image, convert the datatype of the array, and then convert to an actual image. \n",
        "        img_result = np.clip(img_result, 0.0, 255.0)\n",
        "        img_result = img_result.astype(np.uint8)\n",
        "        result = PIL.Image.fromarray(img_result, mode='RGB')\n",
        "        \n",
        "        # Save all the frames in the dream location\n",
        "        result.save(r'/content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Art Creation by AI/{}/img_{}.jpg'.format(dream_name, i+1))\n",
        "        \n",
        "        created_count += 1\n",
        "        if created_count > max_count:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8oN2QaAGVT2"
      },
      "source": [
        "# TASK #10: (VIDEO) CREATE A VIDEO FROM ALL THE FRAMES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "cUHO-rGKrvxX",
        "outputId": "af5afa1f-f7e3-479c-873d-98e51e5aea6f"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zSXpntx-ryHD",
        "outputId": "4436032e-78c3-489e-c572-9083209b9d13"
      },
      "outputs": [],
      "source": [
        "# Unzip the folder\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_name = \"mars_eiffel.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlU4BJ2fFu-a"
      },
      "outputs": [],
      "source": [
        "# Path of all the frames\n",
        "\n",
        "dream_path = 'mars_eiffel'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdcu-z53FvBC"
      },
      "outputs": [],
      "source": [
        "# Define the codec and create VideoWriter object \n",
        "# Download FFmeg \n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID') # FourCC is a 4-byte code used to specify the video codec\n",
        "\n",
        "out = cv2.VideoWriter('deepdreamvideo.avi', fourcc , 5.0, (910, 605)) # Specify the fourCC, frames per second (fps),\n",
        "                                                                            # and frame size\n",
        "# The frames per second value is depends on few important things\n",
        "# 1. The number of frames we have created. Less number of frames brings small fps\n",
        "# 2. The larger the image the bigger the fps value. For example, 1080 pixel image can bring 60 fps "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceElmedwFu8c"
      },
      "outputs": [],
      "source": [
        "for i in range(9999999999999):\n",
        "    \n",
        "    # Get into the dream directory and looks for the number of images and then figure out what is the latest image. Hence with \n",
        "    # this image we are going to start with and let it dream on and on\n",
        "    if os.path.isfile('mars_eiffel/img_{}.jpg'.format(i+1)):\n",
        "        pass\n",
        "    # Figure out how long the dream is \n",
        "    else:\n",
        "        dream_length = i\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "meJ49RlyYjKW",
        "outputId": "0ea27dad-7511-43e2-b8b6-e285eea28a33"
      },
      "outputs": [],
      "source": [
        "dream_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gTfzipi2GjBz",
        "outputId": "1d069d15-84c2-4913-a44d-0131b625afe4"
      },
      "outputs": [],
      "source": [
        "for i in range(dream_length):\n",
        "    \n",
        "    # Build the frames of cv2.VideoWriter\n",
        "    img_path = os.path.join(dream_path,'img_{}.jpg'.format(i)) # join the dream path\n",
        "    \n",
        "    print(img_path) # print the image path \n",
        "    \n",
        "    frame = cv2.imread(img_path)\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7pUBTXMw75-"
      },
      "source": [
        "# GREAT JOB!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XClSC_faDntC"
      },
      "source": [
        "# MINI CHALLENGE SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMa1lgsvDd59"
      },
      "source": [
        "MINI CHALLENGE #1: \n",
        "- How many total parameters exist in inceptionNet V3?\n",
        "- Set include top = True and indicate how many total parameters exist now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CfSvcJqDeoy"
      },
      "outputs": [],
      "source": [
        "Total Params = 23,851,784 (include Top = True)\n",
        "Total params: 21,802,784 (include Top = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udOdEbWOw_XI"
      },
      "source": [
        "MINI CHALLENGE #2: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxYKrjkSw-pn"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.squeeze(Sample_Image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz6l_MiYOhsB"
      },
      "source": [
        "MINI CHALLENGE #3: \n",
        "- Generate the activations for a deeper layer such as 'mixed8' and 'mixed9'.\n",
        "- What is the size of the generated activations?\n",
        "- Combine 4 activations from early and deeper layers such as 'mixed3', 'mixed5', 'mixed8', 'mixed9'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4hOkTf7EUUt"
      },
      "outputs": [],
      "source": [
        "names = ['mixed8', 'mixed9']\n",
        "# shape=(1, 13, 21, 1280)\n",
        "names = ['mixed3', 'mixed5', 'mixed8', 'mixed9']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG8y6b4rzEnR"
      },
      "source": [
        "MINI CHALLENGE #4: \n",
        "- Using tf.GradientTape(), calculate the gradient of y = x^4 + x^5 at x = 5\n",
        "- Verify your answer by manually differentation the equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3AC78Q4y9pV"
      },
      "outputs": [],
      "source": [
        "x = tf.constant(5.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = (x * x * x * x) + (x * x * x * x * x)\n",
        "dy_dx = g.gradient(y, x) # Will compute to 12\n",
        "dy_dx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y84B37_XzKI0"
      },
      "outputs": [],
      "source": [
        "# 500+3125 = 3625"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru61OUfX0DZI"
      },
      "source": [
        "MINI CHALLENGE #5: \n",
        "- What is the sum of all losses when 'mixed3' layer is the only layer used for activations generation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv6CZy7S0Bn9"
      },
      "outputs": [],
      "source": [
        "# <tf.Tensor: shape=(), dtype=float32, numpy=0.36584973>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Creative AI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
